
"""
Simulating use by software
that will call gguf-llama.cpp as if it were a cloud api,
e.g.
with a model type, parameters, and conversation 
history with system prompt...
even thought that is not exactly how
llama.cpp itself is set up to work.


1. user uses the pack_unpack.py function
to package what to sent to call_gguf.py


2. 


"""